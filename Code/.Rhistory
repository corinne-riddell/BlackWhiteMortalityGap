plot(theta, prior, type='l')
# (iii) posterior (ignore normalizing constant)
post = likelihood*prior / sum(likelihood*prior)
plot(theta, post, type='l', xlim=c(4,7))
abline(v=mean(x), col='purple')
sum(post)
10.78-8.68
90/30
3*85
1000000
1000000/60
38.40+12.52
90+97
17.18 + 12.07
344.97+114.72
344.97-114.72
230.25 + 30
2700/12
2700/24
5292/12
28*2
508/24
7475/24
7475/12
278.32 + 178.68
457 / 2
228.5 + 15
457 -
243.5
164/50
3.28*85
library(foreign)
library(ggplot2)
library(reshape2)
library(INLA)
bluesky_extract_distribution24 = function(day, spatial_subset){
bluesky_extract_distribution24 = function(day, spatial_subset){
require(raster)
load('/Users/kathryn/Dropbox/work/phd/manuscript 3 - EHP/code/2_bluesky/daspatial.rdata')
daspatial.proj <- spTransform(daspatial, CRS("+proj=longlat +ellps=WGS84 +no_defs"))
folder = format(day,"%d%b%Y")
file = paste("/Users/kathryn/Dropbox/work/phd/manuscript 3 - EHP/data/blueskyAM",'/', folder,"/",folder,".nc",sep="")
test = file_test("-f",file )
blue.stack = brick(file, varname = "PM25")
blue.list = unstack(blue.stack)
# Subsequent 24 hour forecast
blue.day24 = blue.list[4:27]
blue.day24 = stack(blue.day24)
blue.mean24 = calc(blue.day24,mean)
blue.max24 = calc(blue.day24,max)
bb = extent(-143.55, -104.65, 40.45, 65.55)
extent(blue.mean24) <- bb
extent(blue.max24) <- bb
e_24mean = extract(blue.mean24,daspatial.proj)
e_24max = extract(blue.max24,daspatial.proj)
daspatial.proj@data$blue_24mean = e_24mean
daspatial.proj@data$blue_24max = e_24max
# population weighted average for LHAs
LHA_average_24mean = LHA_average_24max = numeric()
LHAs = spatial_subset #unique(daspatial.proj@data$LHA_ID)
for (LHA in LHAs){
sub = daspatial.proj@data[daspatial.proj@data$LHA_ID==LHA,]
LHA_average_24mean = c(LHA_average_24mean, weighted.mean(sub$blue_24mean,sub$Pop))
LHA_average_24max = c(LHA_average_24max, weighted.mean(sub$blue_24max,sub$Pop))
}
LHA_average_24 = data.frame(LHAs,LHA_average_24mean,LHA_average_24max)
LHA_average_24$date = rep(day,length(LHAs))
LHA_average_24$level = ifelse( max(LHA_average_24$LHA_average_24mean)>24, 'Moderate smoke', 'Low smoke')
LHA_average_24$level = ifelse( max(LHA_average_24$LHA_average_24mean)>59, 'High smoke', LHA_average_24$level)
colnames(LHA_average_24) = c("ID","bluesky_mean","bluesky_max","forecast_morning_of", "level")
return(LHA_average_24)
}
bluesky_extract_distribution48 = function(day, spatial_subset){
require(raster)
load('/Users/kathryn/Dropbox/work/phd/manuscript 3 - EHP/code/2_bluesky/daspatial.rdata')
daspatial.proj <- spTransform(daspatial, CRS("+proj=longlat +ellps=WGS84 +no_defs"))
folder = format(day,"%d%b%Y")
file = paste("/Users/kathryn/Dropbox/work/phd/manuscript 3 - EHP/data/blueskyAM",'/', folder,"/",folder,".nc",sep="")
test = file_test("-f",file )
blue.stack = brick(file, varname = "PM25")
blue.list = unstack(blue.stack)
# 48 hr forecast
blue.day48 = blue.list[28:51]
blue.day48 = stack(blue.day48)
blue.mean48 = calc(blue.day48,mean)
blue.max48 = calc(blue.day48,max)
bb = extent(-143.55, -104.65, 40.45, 65.55)
extent(blue.mean48) <- bb
extent(blue.max48) <- bb
e_48mean = extract(blue.mean48,daspatial.proj)
e_48max = extract(blue.max48,daspatial.proj)
daspatial.proj@data$blue_48mean = e_48mean
daspatial.proj@data$blue_48max = e_48max
# population weighted average for LHAs
LHA_average_48mean = LHA_average_48max = numeric()
LHAs = spatial_subset #unique(daspatial.proj@data$LHA_ID)
for (LHA in LHAs){
sub = daspatial.proj@data[daspatial.proj@data$LHA_ID==LHA,]
LHA_average_48mean = c(LHA_average_48mean, weighted.mean(sub$blue_48mean,sub$Pop))
LHA_average_48max = c(LHA_average_48max, weighted.mean(sub$blue_48max,sub$Pop))
}
LHA_average_48 = data.frame(LHAs,LHA_average_48mean,LHA_average_48max)
LHA_average_48$date = rep(day,length(LHAs))
LHA_average_48$level = ifelse( max(LHA_average_48$LHA_average_48mean)>19, 'Moderate smoke', 'Low smoke')
LHA_average_48$level = ifelse( max(LHA_average_48$LHA_average_48mean)>59, 'High smoke', LHA_average_48$level)
colnames(LHA_average_48) = c("ID","bluesky_mean","bluesky_max","forecast_morning_of", "level")
return(LHA_average_48)
}
days = seq(as.Date("2015-07-02"), as.Date("2015-07-10"), "days")
lha_sub = read.dbf('/Users/kathryn/Dropbox/work/phd/manuscript 3 - EHP/data/shapefiles/exposure_area.dbf')$LHA_ID
bs24 = lapply(days, FUN = bluesky_extract_distribution24, spatial_subset=lha_sub)
bs48 = lapply(days, FUN = bluesky_extract_distribution48, spatial_subset=lha_sub)
setwd('/Users/kathryn/Dropbox/work/phd/manuscript 3 - EHP/code/3_health_forecasting')
source('health_forecasting_source.R')
# Define the dates
day1 = as.Date("2015-07-02")
dayt = as.Date("2015-07-10")
# Run the models and obtain prediction intervals
# 1. Mean of hourly means
ds1 = read.csv('manuscript3_database_window_horizon.csv')
ds2 = read.csv('manuscript3_database_horizon_1Mean.csv')
ds1 = read.csv('manuscript3_database_window_horizon.csv')
setwd('/Users/kathryn/Dropbox/work/phd/manuscript 3 - EHP/code/3_health_forecasting')
source('health_forecasting_source.R')
setwd('/Users/kathryn/Dropbox/work/phd/manuscript 3 - EHP/code/6_BS_comparison')
ds1 = read.csv('manuscript3_database_window_horizon.csv')
ds2 = read.csv('manuscript3_database_horizon_1Mean.csv')
m24 = run_forecast_model24(day1, dayt, inla.strategy='laplace')
p24 = forecast_prediction_interval24(m24, day1, dayt, N.posterior.samples=1000)
m48 = run_forecast_model48(day1, dayt, inla.strategy='laplace')
p48 = forecast_prediction_interval48(m48, day1, dayt, N.posterior.samples=1000)
save(list(p24=p24, p48=p48), 'results_Nov3_1Mean.RData')
save(list(p24=p24, p48=p48), file.name = 'results_Nov3_1Mean.RData')
save
?save
save(list(p24=p24, p48=p48), file = 'results_Nov3_1Mean.RData')
r1 = list(p24=p24, p48=p48)
save(r1, file = 'results_Nov3_1Mean.RData')
ds1 = read.csv('manuscript3_database_window_horizon.csv')
ds2 = read.csv('manuscript3_database_horizon_2Max.csv')
ds2
m24 = run_forecast_model24(day1, dayt, inla.strategy='laplace')
p24 = forecast_prediction_interval24(m24, day1, dayt, N.posterior.samples=1000)
m48 = run_forecast_model48(day1, dayt, inla.strategy='laplace')
p48 = forecast_prediction_interval48(m48, day1, dayt, N.posterior.samples=1000)
r2 = list(p24=p24, p48=p48)
save(r2, file = 'results_Nov3_2Max.RData')
ds1 = read.csv('manuscript3_database_window_horizon.csv')
ds2 = read.csv('manuscript3_database_horizon_3MaxMax.csv')
ds2
m24 = run_forecast_model24(day1, dayt, inla.strategy='laplace')
p24 = forecast_prediction_interval24(m24, day1, dayt, N.posterior.samples=1000)
m48 = run_forecast_model48(day1, dayt, inla.strategy='laplace')
p48 = forecast_prediction_interval48(m48, day1, dayt, N.posterior.samples=1000)
r3 = list(p24=p24, p48=p48)
save(r3, file = 'results_Nov3_3MaxMax.RData')
r3$p24[[1]]$samp.disp
hist(r3$p24[[1]]$samp.disp)
mean(r3$p24[[1]]$samp.disp)
length(r1$p24)
N = length(r1$p24)
i
i = 1
mean(r1$p24[[1]]$samp.disp)
mean(r2$p24[[1]]$samp.disp)
mean(r3$p24[[1]]$samp.disp)
mean(r1$p24[[1]]$samp.disp)
for(i in 1:N) {
mean1[i] = mean(r1$p24[[i]]$samp.disp)
mean2[i] = mean(r2$p24[[i]]$samp.disp)
mean3[i] = mean(r3$p24[[i]]$samp.disp)
}
mean1 = mean2 = mean3 = c()
for(i in 1:N) {
mean1[i] = mean(r1$p24[[i]]$samp.disp)
mean2[i] = mean(r2$p24[[i]]$samp.disp)
mean3[i] = mean(r3$p24[[i]]$samp.disp)
}
mean1
mean2
mean3
cbind(mean1, mean2, mean3)
mean1 = mean2 = mean3 = c()
for(i in 1:N) {
mean1[i] = mean(r1$p24[[i]]$samp.vis)
mean2[i] = mean(r2$p24[[i]]$samp.vis)
mean3[i] = mean(r3$p24[[i]]$samp.vis)
}
cbind(mean1, mean2, mean3)
cbind(mean1, mean2, mean3)
cbind(mean1, mean2, mean3)
mean(r1$p48[[i]]$samp.disp)
i
source('/Users/kathryn/Dropbox/work/phd/manuscript 3 - EHP/code/5_descriptives/descriptive_source.R')
make_health_graphics2 = function(p24, p48, r24, r48) {
date_reference = data.frame(date=days, date_ref = 1:length(days))
df = df_disp = df_vis = list()
days = seq(as.Date("2015-07-03"), as.Date("2015-07-9"), "days")
for(i in 1:7) {
df[[i]] = integrate_datasets(date_id=(i+1), p24, p48, r24, r48)
df_disp[[i]] = df[[i]]$df_disp
k = length(df_disp[[i]]$p)
df_disp[[i]]$day = rep(days[i], k)
df_vis[[i]] = df[[i]]$df_vis
df_vis[[i]]$day = rep(days[i], k)
}
df_disp2 = do.call(rbind, df_disp)
df_vis2  = do.call(rbind, df_vis)
lpi24 = upi24 = c()
lpi48 = upi48 = c()
for(i in 1:7) {
temp24 = subset(df_disp2, hour == '24-hr' & day==days[i])
lpi24 = c(lpi24, as.numeric(quantile(temp24$p, 0.025)))
upi24 = c(upi24, as.numeric(quantile(temp24$p, 0.975)))
temp48 = subset(df_disp2, hour == '48-hr' & day==days[i])
lpi48 = c(lpi48, as.numeric(quantile(temp48$p, 0.025)))
upi48 = c(upi48, as.numeric(quantile(temp48$p, 0.975)))
}
vline_disp = data.frame(day=days, lpi24, upi24, lpi48, upi48)
vline_melt = melt(vline_disp, id.vars=c('day'))
vline_melt$hour = c(rep('24-hr', 14), rep('48-hr', 14))
vline_melt$variable = NULL
vline_melt$true_y = c(ds2$disp[2:8], ds2$disp[2:8], ds2$disp[3:9], ds2$disp[3:9])
vline_melt2 = melt(vline_melt, id.vars=c('day','hour'))
df_disp2$day = format(df_disp2$day, "%B %d")
df_vis2$day = format(df_vis2$day, "%B %d")
vline_melt2$day  = format(vline_melt2$day, "%B %d")
level24 = level48 = c()
for(i in 2:8) {
level24 = c(level24, unique(r24[[i]]$level))
level48 = c(level48, unique(r48[[i]]$level))
}
data_bg = arrange(unique(df_disp2[,c('day','hour')]), hour)
data_bg$level = c(level24, level48)
colourCats = as.factor(c("Low smoke","Moderate smoke","High smoke"))
g = ggplot(data=df_disp2) +
geom_rect(data = data_bg,aes(fill = level), xmin = -Inf,xmax = Inf,
ymin = -Inf,ymax = Inf,alpha = 0.2)  +
geom_histogram(aes(x=p, ..density..), fill='lightblue', colour='white', size=0.1, binwidth = 35) +
facet_grid(day ~ hour, scales='free')  +
geom_vline(aes(xintercept=value, colour=variable, linetype=variable), data=vline_melt2, size=0.25) +
scale_linetype_manual(values=c('dashed','solid'),
labels = c('95% Prediction Interval Quantiles     ',
'Future observed value'),
name="")  +
scale_colour_manual(values=c('#3A9FBF','black'),
labels = c('95% Prediction Interval Quantiles     ',
'Future observed value'),
name="") + xlim(0,2300) +
xlab('Dispensation counts')  + ylab(paste0('Relative frequency', '\n')) +
scale_y_discrete(breaks=NULL) +
scale_fill_manual(breaks=c("Low smoke","Moderate smoke","High smoke"),
values = c('#FF4949','#66C98F','#E3DC47'),
drop=FALSE, limits=levels(colourCats),
name="")
g1 = gg_pretty_descriptive(g)
# VISITS
for(i in 1:7) {
df[[i]] = integrate_datasets(date_id=(i+1), p24, p48, r24, r48)
df_vis[[i]] = df[[i]]$df_vis
k = length(df_vis[[i]]$p)
df_vis[[i]]$day = rep(days[i], k)
df_vis[[i]] = df[[i]]$df_vis
df_vis[[i]]$day = rep(days[i], k)
}
df_vis2 = do.call(rbind, df_vis)
df_vis2  = do.call(rbind, df_vis)
lpi24 = upi24 = c()
lpi48 = upi48 = c()
for(i in 1:7) {
temp24 = subset(df_vis2, hour == '24-hr' & day==days[i])
lpi24 = c(lpi24, as.numeric(quantile(temp24$p, 0.025)))
upi24 = c(upi24, as.numeric(quantile(temp24$p, 0.975)))
temp48 = subset(df_vis2, hour == '48-hr' & day==days[i])
lpi48 = c(lpi48, as.numeric(quantile(temp48$p, 0.025)))
upi48 = c(upi48, as.numeric(quantile(temp48$p, 0.975)))
}
vline_vis = data.frame(day=days, lpi24, upi24, lpi48, upi48)
vline_melt = melt(vline_vis, id.vars=c('day'))
vline_melt$hour = c(rep('24-hr', 14), rep('48-hr', 14))
vline_melt$variable = NULL
vline_melt$true_y = c(ds2$vis[2:8], ds2$vis[2:8], ds2$vis[3:9], ds2$vis[3:9])
vline_melt2 = melt(vline_melt, id.vars=c('day','hour'))
df_vis2$day = format(df_vis2$day, "%B %d")
df_vis2$day = format(df_vis2$day, "%B %d")
vline_melt2$day  = format(vline_melt2$day, "%B %d")
level24 = level48 = c()
for(i in 2:8) {
level24 = c(level24, unique(r24[[i]]$level))
level48 = c(level48, unique(r48[[i]]$level))
}
data_bg = arrange(unique(df_vis2[,c('day','hour')]), hour)
data_bg$level = c(level24, level48)
colourCats = as.factor(c("Low smoke","Moderate smoke","High smoke"))
g = ggplot(data=df_vis2) +
geom_rect(data = data_bg,aes(fill = level), xmin = -Inf,xmax = Inf,
ymin = -Inf,ymax = Inf,alpha = 0.2)  +
geom_histogram(aes(x=p, ..density..), fill='lightblue', colour='white', size=0.1, binwidth = 15) +
facet_grid(day ~ hour, scales='free')  +
geom_vline(aes(xintercept=value, colour=variable, linetype=variable), data=vline_melt2, size=0.25) +
scale_linetype_manual(values=c('dashed','solid'),
labels = c('95% Prediction Interval Quantiles     ',
'Future observed value'),
name="")  +
scale_colour_manual(values=c('#3A9FBF','black'),
labels = c('95% Prediction Interval Quantiles     ',
'Future observed value'),
name="") + xlim(0,1000) +
xlab('Physician visit counts')  + ylab(paste0('Relative frequency', '\n')) +
scale_y_discrete(breaks=NULL) +
scale_fill_manual(breaks=c("Low smoke","Moderate smoke","High smoke"),
values = c('#FF4949','#66C98F','#E3DC47'),
drop=FALSE, limits=levels(colourCats),
name="")
g2 = gg_pretty_descriptive(g)
return(list(g1=g1, g2=g2))
}
p24
g = make_health_graphics2(p24, p48, bs24, bs48)
date_reference = data.frame(date=days, date_ref = 1:length(days))
df = df_disp = df_vis = list()
days = seq(as.Date("2015-07-03"), as.Date("2015-07-9"), "days")
days
integrate_datasets
p24[[1]]$samp.disp
setwd("~/Documents/BlackWhiteMortalityGap/Code")
source('4_smoothing_time_src.R')
source('4_smoothing_time_src.R')
load('/Users/kathryn/Dropbox/BlackWhiteGap/Data/main_datasets.Rdata')
race = 'Black'
sex = 'Female'
cod = 'Injuries'
state = 'Alabama'
selected_vars = c('Age', 'Sex2', 'Race2', 'COD2', 'Year', 'Count', 'Population')
ds = dat.clean[(dat.clean$Race2==race &
dat.clean$Sex2==sex &
dat.clean$State2==state &
dat.clean$COD2==cod), selected_vars]
head(ds)
df = data.frame(deaths=ds$Count, pop = ds$Population, age=(ds$Age+1), year=(ds$Year+1))
df
df$censored = ifelse(is.na(df$deaths),1,0)
ds2 = df[order(df$censored), ]
ds_jags = list(deaths = ds2$deaths,
lnpop = log(ds2$pop),
age.bin = ds2$age,
year = ds2$year,
binned = is.na(ds2$deaths),
not.binned = !is.na(ds2$deaths),
n.binned = sum(is.na(ds2$deaths)),
n.not.binned = sum(!is.na(ds2$deaths)),
n.not.binned.plus.1 = sum(!is.na(ds2$deaths)) + 1,
n.rows = sum(is.na(ds2$deaths)) + sum(!is.na(ds2$deaths)),
n.age.bins = length(unique(ds2$age)),
n.years = length(unique(ds2$year)),
binned.id = ds2$censored)
ds_jags
head(dat.clean)
table(dat.clean$Population < 10)
dat.clean$upper_bound = ifelse(dat.clean$Population<9, dat.clean$Population, 9)
head(dat.clean$upper_bound)
hist(dat.clean$upper_bound)
table(dat.clean$upper_bound)
dat.clean[dat.clean$Population<10, ]
head(dat.clean[dat.clean$Population<10, ])
head(dat.clean[dat.clean$Population<10, ], 50)
selected_vars = c('Age', 'Sex2', 'Race2', 'COD2', 'Year', 'Count', 'Population', 'uppper_bound')
ds = dat.clean[(dat.clean$Race2==race &
dat.clean$Sex2==sex &
dat.clean$State2==state &
dat.clean$COD2==cod), selected_vars]
race
dat.clean$upper_bound = ifelse(dat.clean$Population<9, dat.clean$Population, 9)
selected_vars = c('Age', 'Sex2', 'Race2', 'COD2', 'Year', 'Count', 'Population', 'upper_bound')
ds = dat.clean[(dat.clean$Race2==race &
dat.clean$Sex2==sex &
dat.clean$State2==state &
dat.clean$COD2==cod), selected_vars]
df = data.frame(deaths=ds$Count, pop = ds$Population, age=(ds$Age+1), year=(ds$Year+1))
df$censored = ifelse(is.na(df$deaths),1,0)
ds2 = df[order(df$censored), ]
ds_jags = list(deaths = ds2$deaths,
lnpop = log(ds2$pop),
age.bin = ds2$age,
year = ds2$year,
binned = is.na(ds2$deaths),
not.binned = !is.na(ds2$deaths),
n.binned = sum(is.na(ds2$deaths)),
n.not.binned = sum(!is.na(ds2$deaths)),
n.not.binned.plus.1 = sum(!is.na(ds2$deaths)) + 1,
n.rows = sum(is.na(ds2$deaths)) + sum(!is.na(ds2$deaths)),
n.age.bins = length(unique(ds2$age)),
n.years = length(unique(ds2$year)),
binned.id = ds2$censored)
ds_jags
df = data.frame(deaths=ds$Count, pop = ds$Population, age=(ds$Age+1), year=(ds$Year+1), upper_bound = ds$upper_bound)
df$censored = ifelse(is.na(df$deaths),1,0)
ds2 = df[order(df$censored), ]
ds_jags = list(deaths = ds2$deaths,
lnpop = log(ds2$pop),
age.bin = ds2$age,
year = ds2$year,
upper_bound = ds2$upper_bound,
binned = is.na(ds2$deaths),
not.binned = !is.na(ds2$deaths),
n.binned = sum(is.na(ds2$deaths)),
n.not.binned = sum(!is.na(ds2$deaths)),
n.not.binned.plus.1 = sum(!is.na(ds2$deaths)) + 1,
n.rows = sum(is.na(ds2$deaths)) + sum(!is.na(ds2$deaths)),
n.age.bins = length(unique(ds2$age)),
n.years = length(unique(ds2$year)),
binned.id = ds2$censored)
ds_jags
setwd("~/Documents/BlackWhiteMortalityGap/Code")
r_female = read.csv('/Users/kathryn/Documents/BlackWhiteMortalityGap/Code/results_femalesNov4.csv')
r_male = read.csv('/Users/kathryn/Documents/BlackWhiteMortalityGap/Code/results_malesNov4.csv')
r1 = r_female ; r2 = r_male
head(r1) ; head(r2)
r1$X = NULL ; r2$X = NULL
r1
head(r1) ; tail(r1)
r = rbind(r1, r2)
head(r) ; tail(r)
r2$sex = rep('Males', length(r2$race))
head(r2)
r2$sex = rep('Male', length(r2$race))
head(r2)
r = rbind(r1, r2)
head(r) ; tail(r)
require(sqldf)
?sqldf
head(r) ; tail(r)
r2 = sqldf("select * from r order by year, age_bin, sex, race, state")
head(r2)
head(dat.clean)
head(dat.clean, 100)
r2 = sqldf("select * from r order by state, sex, race, age, year, COD ")
head(r) ; tail(r)
r2 = sqldf("select * from r order by state, sex, race, age_bin, year, COD ")
head(r2) ; tail(r2)
head(dat.clean)
write.csv(r2, 'smoothed_results.csv')
plot(r2$deaths, r2$smoothed_deaths)
plot(r2$deaths, r2$smoothed_deaths, pch=16, cex=0.1)
ds1 = r2[r2$race=='Black' & r2$sex=='Male', ]
head(ds1)
require(ggplot2)
ds1 = r2[r2$race=='Black' & r2$sex=='Male' & r2$cod=='Injuries', ]
head(ds1)
& r2$state=='Alabama', ]
ds1 = r2[r2$race=='Black' & r2$sex=='Male' & r2$cod=='Injuries'
& r2$state=='Alabama', ]
head(ds1)
ds2 = ds1[ ,c('deaths', 'smoothed_deaths', 'age_bin')]
ds3 = melt(ds2, id.vars='year')
ds3 = melt(ds2, id.vars=year)
"melt
?melt
ds3 = melt(ds2)
ds3
ds3 = melt(ds2, year)
ds3 = melt(ds2, ds2$year)
ds3
ds3 = melt(ds2, id.vars='year')
ds3 = melt(ds2, id.var='year')
head(ds2)
ds2 = ds1[ ,c('deaths', 'smoothed_deaths', 'age_bin', 'year')]
ds3 = melt(ds2, id.var='year')
head(ds3)
ds3 = melt(ds2, id.var=c('year','age_bin'))
head(ds3)
ggplot(data=ds3) + geom_line(aes(x=year, y=value, col=age_bin))
ggplot(data=ds3) + geom_line(aes(x=year, y=value, col=age_bin)) + facet_grid(~age_bin)
ggplot(data=ds3) + geom_line(aes(x=year, y=value, col=variable)) + facet_grid(~age_bin)
ggplot(data=ds3) + geom_line(aes(x=year, y=value, col=variable)) + facet_grid(age_bin~)
ggplot(data=ds3) + geom_line(aes(x=year, y=value, col=variable)) + facet_grid(age_bin~)
ggplot(data=ds3) + geom_line(aes(x=year, y=value, col=variable)) + facet_grid(age_bin ~ .)
?facet_grid
?facet_wrap
ggplot(data=ds3) + geom_line(aes(x=year, y=value, col=variable)) + facet_wrap(age_bin ~ .)
ggplot(data=ds3) + geom_line(aes(x=year, y=value, col=variable)) + facet_wrap(age_bin)
ggplot(data=ds3) + geom_line(aes(x=year, y=value, col=variable)) + facet_grid(age_bin ~ ., scales='free')
g = ggplot(data=ds3) + geom_line(aes(x=year, y=value, col=variable)) + facet_grid(age_bin ~ ., scales='free')
?ggsave
getwd()
ggsave(g, filename='test.png')
ds1 = r2[r2$race=='Black' & r2$sex=='Male' & r2$state=='Alabama', ]
head(ds1)
ds2 = ds1[ ,c('deaths', 'smoothed_deaths', 'age_bin', 'year')]
ds3 = melt(ds2, id.var=c('year','age_bin', 'cod'))
ds2 = ds1[ ,c('deaths', 'smoothed_deaths', 'age_bin', 'year', 'cod')]
ds3 = melt(ds2, id.var=c('year','age_bin', 'cod'))
head(ds3)
g = ggplot(data=ds3) + geom_line(aes(x=year, y=value, col=variable)) + facet_grid(age_bin ~ cod, scales='free')
g
ggpretty = function(g) {
g = g +
theme(legend.position="top", legend.title=element_blank(),
panel.background = element_rect(fill = '#F9F9FE',color='white'),
axis.text.x = element_text(colour=c('black')),
axis.title.x = element_text(colour = 'black', size=8),
axis.title.y = element_text(colour = 'black', size=8, angle = 90, hjust = 0.5),
strip.background = element_rect(fill="#F1F3FD"))
return(g)
}
g = ggpretty(g)
g
?ggsave
ggsave(g, filename='test.png', width=18, height=30)
g = ggplot(data=ds3) + geom_point(aes(x=year, y=value, col=variable)) + facet_grid(age_bin ~ cod, scales='free')
g = ggpretty(g)
ggsave(g, filename='test.png', width=18, height=30)
