---
title: "Appendix material"
author: "Kathryn Morrison"
date: "December 19, 2016"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Statistical model

There is a single estimated mortality rate for each sub-category of state, year, race, age, sex, and cause of death. We consider the true underlying mortality rate to be *latent* and we estimate it with the observed number of deaths per sub-category relative to the number of at-risk individuals, as described previously. The true risk of mortality cannot be zero and is unlikely to exceed 0.1, but these extreme values may occur when the at-risk population is small. To address the challenges in precisely measuring mortality rate with discrete numbers, we perform temporal smoothing using a Bayesian autoregressive approach.   

We denote the true underlying mortality rate as $\lambda$, the observed number of deaths as $D$ and the at-risk population as $P$. For each given state, race, age, sex, and cause of death subgroup, we model the deaths per year as a Poisson random variable, with mean $\mu_t$ (the expected number of deaths per year) that is equal to the mortality rate multiplied by the population: $\lambda_t \times P_t =\frac{D_t}{P_t} \times P_t = D_t$.    

$D_t \sim Poisson(\mu_t)$ 

$\mu_t = exp[log(\lambda_t) + log(P_t)]$  

We log transform the expected value because the mortality rate tends to be heavily right skewed but approximately log-normal. This transformation allows us to model the log rate as autoregressive to smooth between years: 


$log(\lambda_t) \sim N(\ log(\lambda_{t-1}),\ \tau)$

For the first year, a weakly informative prior is placed on the mortality rate:

$log(\lambda_t) \sim N(-4, \ 0.1)$

And the prior in the variance is also weakly informative:

$\tau \sim gamma(0.01, 0.01)$


This autoregressive approach to smoothing addresses the issues with small population sizes causing unrealistic mortality rates in some sub-categories. However, there was also the additional challenge of corsened data, where cells with counts between one and nine were binned into a single category. To estimate the mortality rate in these cells, we use a truncated Poisson bounded between 1 and an upper bound, where the bound is the smaller of 9 or the population size in that sub category. 

